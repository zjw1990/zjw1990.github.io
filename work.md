---
layout: work
title: work
slug: /work
items:
  - title: Time Series Forecasting
    image:
      src: /assets/img/work/time.png
      alt: sand
    description: Forecasting time sereis using deep learning.

  - title: Large Language Models
    image:
      src: /assets/img/work/_llm.png
      alt: sand
    description: I am interested in LLM's domain adaption techniques. Also I hope to explore the explainabiliy for LLMs (Transformer behind it).
  
  - title: Machine Translation
    image:
      src: /assets/img/work/mt.png
      alt: water
    description: My expertise includes unsupervised machine translation and low-resource machine translation. 

  - title: Speech Translation
    image:
      src: /assets/img/work/speech.png
      alt: water
    description: I have been working on Speech Translation in recent years. I am interested in multi-language speech translation and knowledge transferring in Speech Translation.
---

I am passionate about exploring deep learning applications, focusing on areas such as [forecasting](https://en.wikipedia.org/wiki/Time_series), [language models](https://en.wikipedia.org/wiki/Large_language_model), and [translation techniques](https://en.wikipedia.org/wiki/Machine_translation). My research delves into the development and implementation of advanced deep learning algorithms to address complex problems in diverse fields. In the realm of forecasting, I aim to enhance predictive accuracy through innovative models, including time series analysis and machine learning methods. My interest in language models centers on understanding and generating human language, utilizing cutting-edge architectures like transformers to drive improvements in natural language processing tasks. Additionally, I am dedicated to advancing translation techniques, particularly through neural machine translation, with the goal of enhancing the quality and contextual relevance of translations across various languages.

<br />
<br />
